{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch.nn.functional as F\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_U_I(data, file):\n",
    "    # [user, item]\n",
    "    U_I = []\n",
    "    max_user = 0\n",
    "    max_item = 0\n",
    "    with open('../datasets/'+ data +'/' + file , 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for i in lines:\n",
    "            elements = i.split()\n",
    "            sharer = int(elements[0])\n",
    "            item = int(elements[1])\n",
    "            participant = int(elements[2])\n",
    "            max_user = max(sharer, participant, max_user)\n",
    "            max_item = max(max_item, item)\n",
    "            U_I.append([sharer, item])\n",
    "            U_I.append([participant, item])\n",
    "    data = np.ones(len(U_I))\n",
    "    users, items = list(zip(*U_I))\n",
    "    matrix = csr_matrix((data, (users,items)), shape = (max_user + 1, max_item + 1))\n",
    "\n",
    "    x = matrix.nonzero()\n",
    "    data = np.ones(len(x[0]))\n",
    "    # pdb.set_trace()\n",
    "    matrix = csr_matrix((data, (list(x[0]), list(x[1]))), shape = (max_user + 1, max_item + 1))\n",
    "    # matrix = torch.sparse_coo_tensor([list(x[0]), list(x[1])], data, (self.numUsers, self.numItems))\n",
    "    U_I = []\n",
    "    for i in range(len(x[0])):\n",
    "        U_I.append([x[0][i], x[1][i]])\n",
    "\n",
    "\n",
    "    return U_I, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_U_I_U(data, file):\n",
    "    # [user, item, user]\n",
    "    U_I_U = []\n",
    "    with open('../datasets/'+ data +'/' + file , 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for i in lines:\n",
    "            elements = i.split()\n",
    "            sharer = int(elements[0])\n",
    "            item = int(elements[1])\n",
    "            participant = int(elements[2])\n",
    "            U_I_U.append([sharer, item, participant])\n",
    "    return U_I_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_I_train, matrix_train = read_U_I('BeiBei', 'train.txt')\n",
    "U_I_U_test = read_U_I_U('BeiBei', 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_I_train_dict = {}\n",
    "for pair in U_I_train:\n",
    "    u = pair[0]\n",
    "    i = pair[1]\n",
    "    if u not in U_I_train_dict:\n",
    "        U_I_train_dict[u] = [i]\n",
    "    else:\n",
    "        U_I_train_dict[u].append(i)\n",
    "# U_I_test_dict = {}\n",
    "# for pair in U_I_test:\n",
    "#     u = pair[0]\n",
    "#     i = pair[1]\n",
    "#     if u not in U_I_test_dict:\n",
    "#         U_I_test_dict[u] = [i]\n",
    "#     else:\n",
    "#         U_I_test_dict[u].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_social_relation(data):\n",
    "    # [user, user]\n",
    "    social = []\n",
    "    friendship = {}\n",
    "    with open('../datasets/'+ data +'/' + 'social_relation.txt','r') as f:\n",
    "        lines = f.readlines()\n",
    "        for i in lines:\n",
    "            elements = i.split()\n",
    "            u1 = int(elements[0])\n",
    "            u2 = int(elements[1])\n",
    "            social.append([u1, u2])\n",
    "            if u1 not in friendship:\n",
    "                friendship[u1] = [u2]\n",
    "            else:\n",
    "                friendship[u1].append(u2)\n",
    "            if u2 not in friendship:\n",
    "                friendship[u2] = [u1]\n",
    "            else:\n",
    "                friendship[u2].append(u1)\n",
    "    for k,v in friendship.items():\n",
    "        friendship[k] = list(set(v))\n",
    "    return social, friendship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, friendship = read_social_relation('brightkite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for u_i_u in U_I_U_test:\n",
    "    u1 = u_i_u[0]\n",
    "    u2 = u_i_u[2]\n",
    "    score = F.cosine_similarity(t.tensor(matrix_train[u1].toarray()), t.tensor(matrix_train[u2].toarray())).item()\n",
    "    result.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0404371828025607"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef1329b533710657f9b10e9fd6690cd949a8162d924ea46c1fe7e4c36756f4a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
